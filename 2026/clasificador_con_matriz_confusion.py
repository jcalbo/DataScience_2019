"""
================================================================================
EJEMPLO EDUCATIVO: CLASIFICADOR CON MATRIZ DE CONFUSI√ìN
================================================================================
Autor: Profesor de Machine Learning
Objetivo: Demostrar el uso de un clasificador cl√°sico en scikit-learn y c√≥mo
          interpretar los resultados mediante una matriz de confusi√≥n.

Este ejemplo utiliza el dataset de C√°ncer de Mama de Wisconsin (Breast Cancer),
uno de los datasets m√°s utilizados para ense√±ar clasificaci√≥n binaria.

Contenido:
1. Carga y exploraci√≥n del dataset
2. Preprocesamiento de datos
3. Divisi√≥n en conjuntos de entrenamiento y prueba
4. Entrenamiento del modelo (Random Forest)
5. Evaluaci√≥n con matriz de confusi√≥n
6. Interpretaci√≥n de m√©tricas

================================================================================
"""

# =============================================================================
# 1. IMPORTACI√ìN DE LIBRER√çAS
# =============================================================================
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    confusion_matrix,
    ConfusionMatrixDisplay,
    classification_report,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score
)

# Configuraci√≥n para reproducibilidad
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)


def cargar_y_explorar_datos():
    """
    Carga el dataset de c√°ncer de mama y muestra informaci√≥n b√°sica.
    
    El dataset contiene:
    - 569 muestras
    - 30 caracter√≠sticas (features) num√©ricas
    - 2 clases: maligno (0) y benigno (1)
    """
    print("=" * 70)
    print("1. CARGA Y EXPLORACI√ìN DEL DATASET")
    print("=" * 70)
    
    # Cargar el dataset
    datos = load_breast_cancer()
    
    X = datos.data      # Caracter√≠sticas (features)
    y = datos.target    # Etiquetas (labels)
    
    print(f"\nüìä Dataset: {datos.DESCR.split(chr(10))[0]}")
    print(f"\nüìå Dimensiones de X (caracter√≠sticas): {X.shape}")
    print(f"   ‚Üí {X.shape[0]} muestras")
    print(f"   ‚Üí {X.shape[1]} caracter√≠sticas por muestra")
    
    print(f"\nüìå Clases del problema:")
    for i, nombre_clase in enumerate(datos.target_names):
        conteo = np.sum(y == i)
        porcentaje = (conteo / len(y)) * 100
        print(f"   ‚Üí Clase {i} ({nombre_clase}): {conteo} muestras ({porcentaje:.1f}%)")
    
    print(f"\nüìå Primeras 5 caracter√≠sticas:")
    for i, nombre in enumerate(datos.feature_names[:5]):
        print(f"   {i+1}. {nombre}")
    print("   ...")
    
    return X, y, datos.target_names


def preprocesar_datos(X, y):
    """
    Preprocesa los datos:
    1. Divide en conjuntos de entrenamiento (80%) y prueba (20%)
    2. Escala las caracter√≠sticas usando StandardScaler
    
    ¬øPor qu√© escalar?
    - Muchos algoritmos funcionan mejor cuando las caracter√≠sticas
      est√°n en la misma escala.
    - StandardScaler transforma los datos para que tengan media 0
      y desviaci√≥n est√°ndar 1.
    """
    print("\n" + "=" * 70)
    print("2. PREPROCESAMIENTO DE DATOS")
    print("=" * 70)
    
    # Divisi√≥n de datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.20,        # 20% para prueba
        random_state=RANDOM_STATE,
        stratify=y             # Mantener proporci√≥n de clases
    )
    
    print(f"\nüìå Divisi√≥n de datos:")
    print(f"   ‚Üí Entrenamiento: {X_train.shape[0]} muestras ({100*X_train.shape[0]/len(y):.0f}%)")
    print(f"   ‚Üí Prueba: {X_test.shape[0]} muestras ({100*X_test.shape[0]/len(y):.0f}%)")
    
    # Escalado de caracter√≠sticas
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)  # Ajustar y transformar
    X_test_scaled = scaler.transform(X_test)        # Solo transformar
    
    print(f"\nüìå Escalado aplicado (StandardScaler):")
    print(f"   ‚Üí Media antes: {X_train[:, 0].mean():.2f}")
    print(f"   ‚Üí Media despu√©s: {X_train_scaled[:, 0].mean():.2f}")
    print(f"   ‚Üí Desv. Est. antes: {X_train[:, 0].std():.2f}")
    print(f"   ‚Üí Desv. Est. despu√©s: {X_train_scaled[:, 0].std():.2f}")
    
    return X_train_scaled, X_test_scaled, y_train, y_test


def entrenar_modelo(X_train, y_train):
    """
    Entrena un clasificador Random Forest.
    
    ¬øPor qu√© Random Forest?
    - Es un algoritmo de ensemble que combina m√∫ltiples √°rboles de decisi√≥n
    - Robusto ante overfitting
    - No requiere mucho ajuste de hiperpar√°metros
    - Funciona bien con datos de alta dimensionalidad
    """
    print("\n" + "=" * 70)
    print("3. ENTRENAMIENTO DEL MODELO")
    print("=" * 70)
    
    print("\nüìå Algoritmo: Random Forest Classifier")
    print("   ‚Üí Tipo: Ensemble de √°rboles de decisi√≥n")
    print("   ‚Üí Hiperpar√°metros:")
    
    modelo = RandomForestClassifier(
        n_estimators=100,           # N√∫mero de √°rboles
        max_depth=10,               # Profundidad m√°xima
        min_samples_split=5,        # M√≠nimo de muestras para dividir
        random_state=RANDOM_STATE
    )
    
    print(f"      ‚Ä¢ n_estimators: 100 (n√∫mero de √°rboles)")
    print(f"      ‚Ä¢ max_depth: 10 (profundidad m√°xima)")
    print(f"      ‚Ä¢ min_samples_split: 5")
    
    # Entrenamiento
    print("\nüîÑ Entrenando modelo...")
    modelo.fit(X_train, y_train)
    print("‚úÖ Modelo entrenado exitosamente!")
    
    return modelo


def evaluar_modelo(modelo, X_test, y_test, nombres_clases):
    """
    Eval√∫a el modelo entrenado y genera la matriz de confusi√≥n.
    
    M√©tricas importantes:
    - Accuracy: Proporci√≥n de predicciones correctas
    - Precision: De los positivos predichos, ¬øcu√°ntos son realmente positivos?
    - Recall (Sensibilidad): De los positivos reales, ¬øcu√°ntos detectamos?
    - F1-Score: Media arm√≥nica entre Precision y Recall
    """
    print("\n" + "=" * 70)
    print("4. EVALUACI√ìN DEL MODELO")
    print("=" * 70)
    
    # Realizar predicciones
    y_pred = modelo.predict(X_test)
    
    # Calcular m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    print("\nüìä M√âTRICAS DE EVALUACI√ìN:")
    print("-" * 40)
    print(f"   Accuracy:  {accuracy:.4f}  ({accuracy*100:.2f}%)")
    print(f"   Precision: {precision:.4f}  ({precision*100:.2f}%)")
    print(f"   Recall:    {recall:.4f}  ({recall*100:.2f}%)")
    print(f"   F1-Score:  {f1:.4f}  ({f1*100:.2f}%)")
    
    # Reporte de clasificaci√≥n detallado
    print("\nüìã REPORTE DE CLASIFICACI√ìN DETALLADO:")
    print("-" * 40)
    print(classification_report(y_test, y_pred, target_names=nombres_clases))
    
    # Calcular matriz de confusi√≥n
    cm = confusion_matrix(y_test, y_pred)
    
    return y_pred, cm


def mostrar_matriz_confusion(y_test, y_pred, nombres_clases):
    """
    Visualiza la matriz de confusi√≥n con una explicaci√≥n detallada.
    
    La matriz de confusi√≥n muestra:
    - Verdaderos Positivos (VP): Predichos como positivos y son positivos
    - Verdaderos Negativos (VN): Predichos como negativos y son negativos  
    - Falsos Positivos (FP): Predichos como positivos pero son negativos
    - Falsos Negativos (FN): Predichos como negativos pero son positivos
    """
    print("\n" + "=" * 70)
    print("5. MATRIZ DE CONFUSI√ìN")
    print("=" * 70)
    
    cm = confusion_matrix(y_test, y_pred)
    
    print("\nüìä MATRIZ DE CONFUSI√ìN (valores):")
    print("-" * 40)
    print(f"\n                    PREDICCI√ìN")
    print(f"                 {nombres_clases[0]:^10} {nombres_clases[1]:^10}")
    print(f"              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    print(f"    REAL      ‚îÇ           ‚îÇ           ‚îÇ")
    print(f"  {nombres_clases[0]:^10} ‚îÇ  {cm[0,0]:^7}  ‚îÇ  {cm[0,1]:^7}  ‚îÇ")
    print(f"              ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    print(f"  {nombres_clases[1]:^10} ‚îÇ  {cm[1,0]:^7}  ‚îÇ  {cm[1,1]:^7}  ‚îÇ")
    print(f"              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    
    # Interpretaci√≥n
    print("\nüìñ INTERPRETACI√ìN:")
    print("-" * 40)
    
    # Para clasificaci√≥n binaria de c√°ncer: 0=maligno, 1=benigno
    vn = cm[0, 0]  # Verdaderos Negativos (maligno correcto)
    fp = cm[0, 1]  # Falsos Positivos (maligno predicho como benigno) - ¬°PELIGROSO!
    fn = cm[1, 0]  # Falsos Negativos (benigno predicho como maligno)
    vp = cm[1, 1]  # Verdaderos Positivos (benigno correcto)
    
    print(f"\n   ‚úÖ Verdaderos Negativos (VN): {vn}")
    print(f"      ‚Üí Casos malignos correctamente identificados")
    
    print(f"\n   ‚úÖ Verdaderos Positivos (VP): {vp}")
    print(f"      ‚Üí Casos benignos correctamente identificados")
    
    print(f"\n   ‚ùå Falsos Positivos (FP): {fp}")
    print(f"      ‚Üí Casos malignos clasificados como benignos")
    print(f"      ‚Üí ¬°Error cr√≠tico en diagn√≥stico m√©dico!")
    
    print(f"\n   ‚ùå Falsos Negativos (FN): {fn}")
    print(f"      ‚Üí Casos benignos clasificados como malignos")
    print(f"      ‚Üí Genera ansiedad innecesaria al paciente")
    
    # Crear visualizaci√≥n
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Matriz de confusi√≥n con valores absolutos
    disp1 = ConfusionMatrixDisplay(
        confusion_matrix=cm,
        display_labels=nombres_clases
    )
    disp1.plot(ax=axes[0], cmap='Blues', values_format='d')
    axes[0].set_title('Matriz de Confusi√≥n\n(Valores Absolutos)', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('Predicci√≥n', fontsize=11)
    axes[0].set_ylabel('Valor Real', fontsize=11)
    
    # Matriz de confusi√≥n normalizada (porcentajes)
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    disp2 = ConfusionMatrixDisplay(
        confusion_matrix=cm_normalized,
        display_labels=nombres_clases
    )
    disp2.plot(ax=axes[1], cmap='Greens', values_format='.2%')
    axes[1].set_title('Matriz de Confusi√≥n\n(Normalizada por Fila)', fontsize=12, fontweight='bold')
    axes[1].set_xlabel('Predicci√≥n', fontsize=11)
    axes[1].set_ylabel('Valor Real', fontsize=11)
    
    plt.suptitle('Evaluaci√≥n del Clasificador Random Forest\nDataset: Breast Cancer Wisconsin', 
                 fontsize=14, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.savefig('matriz_confusion.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    print("\nüíæ Gr√°fica guardada como 'matriz_confusion.png'")


def main():
    """
    Funci√≥n principal que ejecuta todo el pipeline de clasificaci√≥n.
    """
    print("\n" + "‚ñà" * 70)
    print("‚ñà" + " " * 68 + "‚ñà")
    print("‚ñà" + "  CLASIFICADOR DE MACHINE LEARNING CON MATRIZ DE CONFUSI√ìN  ".center(68) + "‚ñà")
    print("‚ñà" + "  Dataset: Breast Cancer Wisconsin  ".center(68) + "‚ñà")
    print("‚ñà" + " " * 68 + "‚ñà")
    print("‚ñà" * 70)
    
    # Paso 1: Cargar datos
    X, y, nombres_clases = cargar_y_explorar_datos()
    
    # Paso 2: Preprocesar
    X_train, X_test, y_train, y_test = preprocesar_datos(X, y)
    
    # Paso 3: Entrenar
    modelo = entrenar_modelo(X_train, y_train)
    
    # Paso 4: Evaluar
    y_pred, cm = evaluar_modelo(modelo, X_test, y_test, nombres_clases)
    
    # Paso 5: Visualizar matriz de confusi√≥n
    mostrar_matriz_confusion(y_test, y_pred, nombres_clases)
    
    # Resumen final
    print("\n" + "=" * 70)
    print("6. RESUMEN Y CONCLUSIONES")
    print("=" * 70)
    print("""
    üìù PUNTOS CLAVE DEL EJERCICIO:
    
    1. La matriz de confusi√≥n es fundamental para entender el comportamiento
       de un clasificador m√°s all√° de la simple accuracy.
    
    2. En problemas m√©dicos, los Falsos Negativos (FN) pueden ser m√°s
       cr√≠ticos que los Falsos Positivos (FP).
    
    3. El preprocesamiento (escalado) mejora el rendimiento de muchos
       algoritmos de Machine Learning.
    
    4. Random Forest es un buen punto de partida por su robustez y
       facilidad de uso.
    
    5. Siempre dividir los datos en entrenamiento y prueba para
       evaluar la capacidad de generalizaci√≥n del modelo.
    """)
    
    print("=" * 70)
    print("FIN DEL EJEMPLO")
    print("=" * 70)


if __name__ == "__main__":
    main()


